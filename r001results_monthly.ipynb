{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["3ueDCFLa4kHQ"],"toc_visible":true,"authorship_tag":"ABX9TyO8sdGzma7dSOT2I3xNv7WQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **DATA INPUT**"],"metadata":{"id":"CeOiHf9f4gPT"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.lines import Line2D\n","import numpy as np\n","import itertools\n","from joblib import Parallel, delayed\n","import os\n","import multiprocessing\n","import json\n","import random\n","\n","import sklearn.model_selection as skm\n","import statsmodels.api as sm\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import ParameterGrid, GridSearchCV\n","from sklearn.svm import SVR\n","\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.stattools import adfuller\n","from statsmodels.tsa.ar_model import AutoReg\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","import statsmodels.api as sm\n","\n","from scipy.interpolate import Akima1DInterpolator\n","from scipy.interpolate import barycentric_interpolate\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, LSTM, Dropout, SimpleRNN, GRU, Input, Concatenate\n","from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop, Adamax, Adagrad, Nadam\n","from tensorflow.keras.activations import elu, relu, swish\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"3iajdJZQ4i53"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datas = pd.read_csv(\"aaaaa.csv\")"],"metadata":{"id":"Cdn8iYr-40wj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Index Generator"],"metadata":{"id":"NR40UccIXJdR"}},{"cell_type":"code","source":["random.seed(42)"],"metadata":{"id":"lVWtI9KfYO6Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This was made to ensure the same indices were removed as the test set for all the models."],"metadata":{"id":"CjcigJRZXL7P"}},{"cell_type":"code","source":["def generate_non_overlapping_indices(num_observations, num_series, length_series):\n","    max_start_index = num_observations - length_series\n","    available_indices = set(range(max_start_index + 1))  # Create a set of all possible start indices\n","    chosen_indices = []\n","\n","    while len(chosen_indices) < num_series:\n","        start_index = random.choice(list(available_indices))  # Randomly pick from available indices\n","        if all(start_index + i in available_indices for i in range(length_series)):  # Check all needed indices are available\n","            chosen_indices.append(start_index)\n","            # Mark the indices of this block as unavailable\n","            for i in range(length_series):\n","                available_indices.discard(start_index + i)\n","\n","    return sorted(chosen_indices)\n","\n","def expand_indices(start_indices, sequence_length):\n","    full_indices = []\n","    for start in start_indices:\n","        # Append each index from start to start + sequence_length - 1\n","        full_indices.extend(range(start, start + sequence_length))\n","    return full_indices\n","\n","num_observations = 3964\n","\n","sequence_length_week = 7\n","sequence_length_month = 31\n","\n","length_series_week = 7\n","length_series_month = 31"],"metadata":{"id":"w5_-wbDq1tCT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_indices_week = []\n","final_indices_month = []"],"metadata":{"id":"xNoCkcyqHqZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(3):\n","    indices_week = generate_non_overlapping_indices(num_observations, 50, length_series_week)\n","    indices_month = generate_non_overlapping_indices(num_observations, 10, length_series_month)\n","\n","    expanded_indices_week = expand_indices(indices_week, sequence_length_week)\n","    expanded_indices_month = expand_indices(indices_month, length_series_month)\n","\n","    final_indices_week.append(expanded_indices_week)\n","    final_indices_month.append(expanded_indices_month)"],"metadata":{"id":"a7xICeQd7QtF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["expanded_indices_month = final_indices_month[1]"],"metadata":{"id":"a4sf4RUkVC2l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Benchmark Models**"],"metadata":{"id":"3ueDCFLa4kHQ"}},{"cell_type":"code","source":["data = datas.copy()\n","date_indices = data.index[expanded_indices_month]"],"metadata":{"id":"T5ekyN184srI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['Date'] = pd.to_datetime(data[['Year', 'Month', 'Day']])\n","\n","# Set 'Date' as the index\n","data.set_index('Date', inplace=True)"],"metadata":{"id":"pjJBLMt-IJ8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = data[['Concentration']]"],"metadata":{"id":"gHBdZmQxIK9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01cdece7"},"outputs":[],"source":["### We create new dataframes to interpolate\n","data_linear = data.copy()\n","data_poly2 = data.copy()\n","data_poly3 = data.copy()\n","data_poly5 = data.copy()\n","data_neighbor = data.copy()\n","data_time = data.copy()\n","data_spline = data.copy()\n","data_piecewise = data.copy()\n","data_akima = data.copy()\n","data_average = data.copy()\n","data_median = data.copy()"]},{"cell_type":"markdown","source":["## Linear Interpolation"],"metadata":{"id":"XwvgPmN-6SEs"}},{"cell_type":"code","source":["# Step 1: Dataset copy\n","data_linear_copy = data_linear.copy()"],"metadata":{"id":"oEf6RAdy6UfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Seed for reporducibility\n","np.random.seed(42)"],"metadata":{"id":"O0vIJPfv6bYs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 2: Manually introduce NaN values\n","data_linear_copy.loc[date_indices, 'Concentration'] = np.nan"],"metadata":{"id":"hbDHuBBW6r6W"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cc941a0c"},"outputs":[],"source":["# Step 3: Interpolate the deleted NaN values\n","data_linear_copy['Concentration_interpolated'] = data_linear_copy['Concentration'].interpolate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb9774e9"},"outputs":[],"source":["# Step 4: Take only interpolated values and their corresponding dates\n","interpolated_data_linear = data_linear_copy[pd.isna(data_linear_copy['Concentration'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a23856fd"},"outputs":[],"source":["columns_to_remove = ['Concentration']\n","\n","# Use drop to remove the specified columns\n","interpolated_data_linear = interpolated_data_linear.drop(columns=columns_to_remove)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6895d4fe"},"outputs":[],"source":["# Step 5: Merge (via right join) the interpolated dataset with the original dataset using the index\n","merged_data = pd.merge(data_linear, interpolated_data_linear, how='right', left_index=True, right_index=True)"]},{"cell_type":"code","source":["# Step 6: Compute the MSE and MAE\n","mse = mean_squared_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","mae = mean_absolute_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"5b3OPcdZ_WMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9oMXi5Z5bMYR"},"outputs":[],"source":["df_a = merged_data[['Concentration']]\n","df_b = merged_data[['Concentration_interpolated']]\n","values_real = df_a.values.ravel()  # Flatten values to 1D\n","values_inter = df_b.values.ravel()  # Flatten values to 1D\n","merged_data = merged_data.reset_index(drop=True)\n","# Create a dataframe combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': values_real, 'Predicted_Concentration': values_inter}, index=merged_data.index)"]},{"cell_type":"markdown","source":["These are the codes for the 2 graphs that are used for all of the imputations."],"metadata":{"id":"H7S7gGhr8Rsm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7stOlnjYXvh"},"outputs":[],"source":["### Variance Graph\n","\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# To add the perfect prediction line.\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","source":["### Scatter Graph\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Cio981Ir8gRF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d5d8ba1f"},"source":["## 2nd Degree Polynomial Interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9f26a023"},"outputs":[],"source":["# Step 1: Dataset copy\n","data_poly2_copy = data_poly2.copy()"]},{"cell_type":"code","source":["# Seed for reporducibility\n","np.random.seed(42)"],"metadata":{"id":"gx779XWt9PBY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"482fe7f7"},"outputs":[],"source":["# Step 2: Manually introduce NaN values\n","data_poly2_copy.loc[date_indices, 'Concentration'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"183490e5"},"outputs":[],"source":["# Step 3: Interpolate the deleted NaN values with a second-degree polynomial\n","data_poly2_copy['Concentration_interpolated'] = data_poly2_copy['Concentration'].interpolate(method='polynomial', order=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6e70bcbb"},"outputs":[],"source":["# Step 4: Take only interpolated values and their corresponding dates\n","interpolated_data_poly2 = data_poly2_copy[pd.isna(data_poly2_copy['Concentration'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7b3e161e"},"outputs":[],"source":["columns_to_remove = ['Concentration']\n","\n","# Use drop to remove the specified columns\n","interpolated_data_poly2 = interpolated_data_poly2.drop(columns=columns_to_remove)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44978c7d"},"outputs":[],"source":["# Step 5: Merge (via right join) the interpolated dataset with the original dataset using the index\n","merged_data = pd.merge(data_poly2, interpolated_data_poly2, how='right', left_index=True, right_index=True)"]},{"cell_type":"code","source":["# Step 6: Calculate the MSE\n","mse = mean_squared_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"-c5nTeMH_UCr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHhElPrE9q3L"},"outputs":[],"source":["df_a = merged_data[['Concentration']]\n","df_b = merged_data[['Concentration_interpolated']]\n","values_real = df_a.values.ravel()  # Flatten values to 1D\n","values_inter = df_b.values.ravel()  # Flatten values to 1D\n","merged_data = merged_data.reset_index(drop=True)\n","# Create a dataframe combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': values_real, 'Predicted_Concentration': values_inter}, index=merged_data.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iy3BpRDo9q3L"},"outputs":[],"source":["### Variance Graph\n","\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# To add the perfect prediction line.\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","source":["### Scatter Graph\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"vHT4Vl6R9q3M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4BuwoofB-wZN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fJtdc1N7-wx5"},"source":["## 3rd Degree Polynomial Interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfLwo5WT-wx5"},"outputs":[],"source":["# Step 1: Dataset copy\n","data_poly3_copy = data_poly3.copy()"]},{"cell_type":"code","source":["# Seed for reporducibility\n","np.random.seed(42)"],"metadata":{"id":"0ixHKqW5-wx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USXOQ4hk-wx5"},"outputs":[],"source":["# Step 2: Manually introduce NaN values\n","data_poly3_copy.loc[date_indices, 'Concentration'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Ep894zL-wx6"},"outputs":[],"source":["# Step 3: Interpolate the deleted NaN values with a third-degree polynomial\n","data_poly3_copy['Concentration_interpolated'] = data_poly3_copy['Concentration'].interpolate(method='polynomial', order=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ACbFjp4-wx6"},"outputs":[],"source":["# Step 4: Take only interpolated values and their corresponding dates\n","interpolated_data_poly3 = data_poly3_copy[pd.isna(data_poly3_copy['Concentration'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWIzl992-wx6"},"outputs":[],"source":["columns_to_remove = ['Concentration']\n","\n","# Use drop to remove the specified columns\n","interpolated_data_poly3 = interpolated_data_poly3.drop(columns=columns_to_remove)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0jJEt3j-wx6"},"outputs":[],"source":["# Step 5: Merge (via right join) the interpolated dataset with the original dataset using the index\n","merged_data = pd.merge(data_poly3, interpolated_data_poly3, how='right', left_index=True, right_index=True)"]},{"cell_type":"code","source":["# Step 6: Calculate the MSE\n","mse = mean_squared_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"jTu-2ff9_PYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koHjLBOy-wx7"},"outputs":[],"source":["df_a = merged_data[['Concentration']]\n","df_b = merged_data[['Concentration_interpolated']]\n","values_real = df_a.values.ravel()  # Flatten values to 1D\n","values_inter = df_b.values.ravel()  # Flatten values to 1D\n","merged_data = merged_data.reset_index(drop=True)\n","# Create a dataframe combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': values_real, 'Predicted_Concentration': values_inter}, index=merged_data.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"629r7Ki7-wx7"},"outputs":[],"source":["### Variance Graph\n","\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# To add the perfect prediction line.\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","source":["### Scatter Graph\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"vnmf-ZpU-wx8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SHqZdCAd-xc4"},"source":["## Nearest Neighbor Interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"94Y6SozA-xc4"},"outputs":[],"source":["# Step 1: Dataset copy\n","data_neighbor_copy = data_neighbor.copy()"]},{"cell_type":"code","source":["# Seed for reporducibility\n","np.random.seed(42)"],"metadata":{"id":"D7BJ92Hn-xc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvh_FdJc-xc5"},"outputs":[],"source":["# Step 2: Manually introduce NaN values\n","data_neighbor_copy.loc[date_indices, 'Concentration'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WokOBZV-xc5"},"outputs":[],"source":["# Step 3: Interpolate the deleted NaN values with nearest neighbor interpolation\n","data_neighbor_copy['Concentration_interpolated'] = data_neighbor_copy['Concentration'].interpolate(method='nearest')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00FS-KJl-xc6"},"outputs":[],"source":["# Step 4: Take only interpolated values and their corresponding dates\n","interpolated_data_nearest = data_neighbor_copy[pd.isna(data_neighbor_copy['Concentration'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"el96NLWi-xc6"},"outputs":[],"source":["columns_to_remove = ['Concentration']\n","\n","# Use drop to remove the specified columns\n","interpolated_data_nearest = interpolated_data_nearest.drop(columns=columns_to_remove)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hz8voEPQ-xc6"},"outputs":[],"source":["# Step 5: Merge (via right join) the interpolated dataset with the original dataset using the index\n","merged_data = pd.merge(data_neighbor, interpolated_data_nearest, how='right', left_index=True, right_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716883981600,"user_tz":-120,"elapsed":26,"user":{"displayName":"Luis","userId":"12468953136051717863"}},"outputId":"d0e37009-00ba-4cde-e243-074d273959ad","id":"vbb9a1Vl-xc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error (MSE): 299.97\n","Mean Absolute Error (MAE): 13.36\n"]}],"source":["# Step 6: Calculate the MSE\n","mse = mean_squared_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-aeKQqQ-xc7"},"outputs":[],"source":["df_a = merged_data[['Concentration']]\n","df_b = merged_data[['Concentration_interpolated']]\n","values_real = df_a.values.ravel()  # Flatten values to 1D\n","values_inter = df_b.values.ravel()  # Flatten values to 1D\n","merged_data = merged_data.reset_index(drop=True)\n","# Create a dataframe combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': values_real, 'Predicted_Concentration': values_inter}, index=merged_data.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BlA73vGJ-xc8"},"outputs":[],"source":["### Variance Graph\n","\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# To add the perfect prediction line.\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","source":["v### Scatter Graph\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"DVG88Kjm-xc8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aKS2R-zB-y2J"},"source":["## Spline Interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3alOU9U-y2J"},"outputs":[],"source":["# Step 1: Dataset copy\n","data_spline_copy = data_spline.copy()"]},{"cell_type":"code","source":["# Seed for reporducibility\n","np.random.seed(42)"],"metadata":{"id":"o_hy3ftt-y2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aCRtPrIM-y2K"},"outputs":[],"source":["# Step 2: Manually introduce NaN values\n","data_spline_copy.loc[date_indices, 'Concentration'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujqmCTTK-y2L"},"outputs":[],"source":["# Step 3: Interpolate the deleted NaN values with spline interpolation\n","data_spline_copy['Concentration_interpolated'] = data_spline_copy['Concentration'].interpolate(method='spline', order=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuGZSD8e-y2L"},"outputs":[],"source":["# Step 4: Take only interpolated values and their corresponding dates\n","interpolated_data_spline = data_spline_copy[pd.isna(data_spline_copy['Concentration'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y701ZZWw-y2L"},"outputs":[],"source":["columns_to_remove = ['Concentration']\n","\n","# Use drop to remove the specified columns\n","interpolated_data_poly2 = interpolated_data_poly2.drop(columns=columns_to_remove)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77o9Kuxd-y2M"},"outputs":[],"source":["# Step 5: Merge (via right join) the interpolated dataset with the original dataset using the index\n","merged_data = pd.merge(data_spline, interpolated_data_spline, how='right', left_index=True, right_index=True)"]},{"cell_type":"code","source":["# Step 6: Calculate the MSE\n","mse = mean_squared_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"8RzTHZ3hCUXX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdJ8m5wI-y2N"},"outputs":[],"source":["df_a = merged_data[['Concentration']]\n","df_b = merged_data[['Concentration_interpolated']]\n","values_real = df_a.values.ravel()  # Flatten values to 1D\n","values_inter = df_b.values.ravel()  # Flatten values to 1D\n","merged_data = merged_data.reset_index(drop=True)\n","# Create a dataframe combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': values_real, 'Predicted_Concentration': values_inter}, index=merged_data.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbyJ1ndp-y2N"},"outputs":[],"source":["### Variance Graph\n","\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# To add the perfect prediction line.\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","source":["### Scatter Graph\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"gLxFUSDN-y2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FbQGffos-0cL"},"source":["## Piecewise Polynomial Interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKmx8ebG-0cL"},"outputs":[],"source":["# Step 1: Dataset copy\n","data_piecewise_copy = data_piecewise.copy()"]},{"cell_type":"code","source":["# Seed for reporducibility\n","np.random.seed(42)"],"metadata":{"id":"Cyl3cmOc-0cL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Pa-mP9h-0cL"},"outputs":[],"source":["# Step 2: Manually introduce NaN values\n","data_piecewise_copy.loc[date_indices, 'Concentration'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdBHtYKp-0cL"},"outputs":[],"source":["# Step 3: Interpolate the deleted NaN values with piecewise polynomial\n","data_piecewise_copy['Concentration_interpolated'] = data_piecewise_copy['Concentration'].interpolate(method='pchip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-vtD20a-0cM"},"outputs":[],"source":["# Step 4: Take only interpolated values and their corresponding dates\n","interpolated_data_piece = data_piecewise_copy[pd.isna(data_piecewise_copy['Concentration'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VeDLxIn-0cM"},"outputs":[],"source":["columns_to_remove = ['Concentration']\n","\n","# Use drop to remove the specified columns\n","interpolated_data_piece = interpolated_data_piece.drop(columns=columns_to_remove)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TG6g64OA-0cM"},"outputs":[],"source":["# Step 5: Merge (via right join) the interpolated dataset with the original dataset using the index\n","merged_data = pd.merge(data_piecewise, interpolated_data_piece, how='right', left_index=True, right_index=True)"]},{"cell_type":"code","source":["# Step 6: Calculate the MSE\n","mse = mean_squared_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"DKp3WdjRDDRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMQ2h5j--0cM"},"outputs":[],"source":["df_a = merged_data[['Concentration']]\n","df_b = merged_data[['Concentration_interpolated']]\n","values_real = df_a.values.ravel()  # Flatten values to 1D\n","values_inter = df_b.values.ravel()  # Flatten values to 1D\n","merged_data = merged_data.reset_index(drop=True)\n","# Create a dataframe combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': values_real, 'Predicted_Concentration': values_inter}, index=merged_data.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ouEepW0o-0cM"},"outputs":[],"source":["### Variance Graph\n","\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# To add the perfect prediction line.\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","source":["### Scatter Graph\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"4sUMYDBc-0cN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wsOw9hpY-1Hh"},"source":["## Akima Interpolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pO_tCDnU-1Hh"},"outputs":[],"source":["# Step 1: Dataset copy\n","data_akima_copy = data_akima.copy()"]},{"cell_type":"code","source":["# Seed for reporducibility\n","np.random.seed(42)"],"metadata":{"id":"DmU8lyC3-1Hh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2U4TgqeO-1Hh"},"outputs":[],"source":["# Step 2: Manually introduce NaN values\n","data_akima_copy.loc[date_indices, 'Concentration'] = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrdSAX-c-1Hh"},"outputs":[],"source":["nan_mask = pd.isna(data_akima_copy['Concentration'])\n","\n","# Step 3: Create an Akima interpolator for non-NaN values\n","akima_interpolator = Akima1DInterpolator(data_akima_copy.index[~nan_mask], data_akima_copy['Concentration'].dropna())"]},{"cell_type":"code","source":["# Step 4: Interpolate the deleted NaN values with akima interpolation\n","data_akima_copy.loc[nan_mask, 'Concentration_interpolated'] = akima_interpolator(data_akima_copy.index[nan_mask])"],"metadata":{"id":"M1mzHqTjDt9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns_to_remove = ['Concentration']\n","\n","# Use drop to remove the specified columns\n","interpolated_data_akima = interpolated_data_akima.drop(columns=columns_to_remove)"],"metadata":{"id":"-xU90U6fETgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U61rVb6u-1Hi"},"outputs":[],"source":["# Step 4: Take only interpolated values and their corresponding dates\n","interpolated_data_akima = data_akima_copy[nan_mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wR6kF04E-1Hi"},"outputs":[],"source":["# Step 6: Merge (via right join) the interpolated dataset with the original dataset using the index\n","merged_data = pd.merge(data_akima, interpolated_data_akima, how='right', left_index=True, right_index=True)"]},{"cell_type":"code","source":["# Step 7: Calculate the MSE\n","mse = mean_squared_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(merged_data['Concentration'], merged_data['Concentration_interpolated'])\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"b0epBPJzEm0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYhjs5VI-1Hi"},"outputs":[],"source":["df_a = merged_data[['Concentration']]\n","df_b = merged_data[['Concentration_interpolated']]\n","values_real = df_a.values.ravel()  # Flatten values to 1D\n","values_inter = df_b.values.ravel()  # Flatten values to 1D\n","merged_data = merged_data.reset_index(drop=True)\n","# Create a dataframe combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': values_real, 'Predicted_Concentration': values_inter}, index=merged_data.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uf4nmZWm-1Hi"},"outputs":[],"source":["### Variance Graph\n","\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# To add the perfect prediction line.\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","source":["### Scatter Graph\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"j71GR9lj-1Hj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Support Vector Machines"],"metadata":{"id":"X2kGIDyfEqnA"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"SvOxnCiZFuOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define features (X) and target variable (y)\n","X = data.drop(columns=['Concentration'])\n","y = data['Concentration']"],"metadata":{"id":"RtwLqjZnFyH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Initialize the MinMaxScaler\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()  # Separate scaler for the target variable"],"metadata":{"id":"--ddgaEIF0LH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 2: Split the data into training and testing sets\n","X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"],"metadata":{"id":"9Zl9pPTsF2gn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 3: Fit and transform the scaler on the training features and target\n","X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"],"metadata":{"id":"Jg1K0neaF5Va"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 4: Transform the testing features and target using the fitted scaler\n","X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"],"metadata":{"id":"Nj7jkPlLF8Wl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the Support Vector Regression model\n","svm_model = SVR()\n","\n","# Define a broader hyperparameter grid to search\n","param_grid = {\n","    'kernel': ['rbf'],  # Exclude linear kernel\n","    'C': [7],\n","    'gamma': [0.003],\n","    'epsilon': [0.1],\n","    'shrinking': [True, False],\n","}"],"metadata":{"id":"WSqIkKeeF_Z8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the total number of combinations\n","total_combinations = len(list(ParameterGrid(param_grid)))\n","print(\"Total number of different models being tried:\", total_combinations)"],"metadata":{"id":"KATtUKoyG4qn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"390cabea"},"outputs":[],"source":["# Initialize GridSearchCV with SVR, hyperparameter grid, and mean squared error scoring\n","grid_search = GridSearchCV(svm_model, param_grid, scoring='neg_mean_squared_error', cv=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09a18f3f","outputId":"d53cedbc-d5ab-496d-9eb8-f0234b11caa4"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"â–¸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"â–¾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=SVR(),\n","             param_grid={&#x27;C&#x27;: [4], &#x27;epsilon&#x27;: [0.1], &#x27;gamma&#x27;: [0.006],\n","                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;], &#x27;shrinking&#x27;: [True]},\n","             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10, estimator=SVR(),\n","             param_grid={&#x27;C&#x27;: [4], &#x27;epsilon&#x27;: [0.1], &#x27;gamma&#x27;: [0.006],\n","                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;], &#x27;shrinking&#x27;: [True]},\n","             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVR</label><div class=\"sk-toggleable__content fitted\"><pre>SVR()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVR<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVR.html\">?<span>Documentation for SVR</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVR()</pre></div> </div></div></div></div></div></div></div></div></div>"],"text/plain":["GridSearchCV(cv=10, estimator=SVR(),\n","             param_grid={'C': [4], 'epsilon': [0.1], 'gamma': [0.006],\n","                         'kernel': ['rbf'], 'shrinking': [True]},\n","             scoring='neg_mean_squared_error')"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Fit the model with GridSearchCV on the normalized training set\n","grid_search.fit(X_train_scaled, y_train_scaled.ravel())"]},{"cell_type":"code","source":["# Get the best hyperparameters\n","best_params = grid_search.best_params_\n","print(\"Best Hyperparameters:\", best_params)"],"metadata":{"id":"6qawNvJbG7wq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03ef9226"},"outputs":[],"source":["# Get the best model\n","best_svm_model = grid_search.best_estimator_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5df7809"},"outputs":[],"source":["# Test the model on the normalized test set\n","y_test_pred_scaled = best_svm_model.predict(X_test_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fda1f5de"},"outputs":[],"source":["# Inverse transform the predictions to the original scale\n","y_test_pred_scaled = y_test_pred_scaled.reshape(-1, 1)\n","y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cf0209b"},"outputs":[],"source":["# Inverse transform the predictions to the original scale\n","y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)"]},{"cell_type":"code","source":["# MSE and MAE computations\n","mse = mean_squared_error(y_test, y_test_pred)\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(y_test, y_test_pred)\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"LoKzFpjAHCyh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_flat = np.squeeze(y_test_pred)\n","actual_values_flat = y_test.values.ravel()\n","y_test = y_test.reset_index(drop=True)\n","\n","# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"qpe3egXfHNZ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Feedforward Neural Networks"],"metadata":{"id":"_XgDTCfxHX_f"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"f9Uqnea-Hcb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03f55065"},"outputs":[],"source":["# Define features (X) and target variable (y)\n","X = data.drop(columns=['Concentration'])\n","y = data['Concentration']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ea93a83"},"outputs":[],"source":["# Step 1: Initialize the MinMaxScaler\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()  # Separate scaler for the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42a4d9b4"},"outputs":[],"source":["# Step 2: Split the data into training and testing sets\n","X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bd71bcb"},"outputs":[],"source":["# Step 3: Fit and transform the scaler on the training features and target\n","X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7e632998"},"outputs":[],"source":["# Step 4: Transform the testing features and target using the fitted scaler\n","X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"]},{"cell_type":"code","source":["# Step 5: Define and compile the neural network model\n","model = Sequential()\n","model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='elu'))\n","model.add(Dense(32, activation='elu', kernel_regularizer=l2(0.0001)))  # L2 regularization\n","model.add(Dense(16, activation='elu', kernel_regularizer=l2(0.0001)))\n","model.add(Dense(8, activation='elu', kernel_regularizer=l2(0.0001)))\n","model.add(Dense(4, activation='elu', kernel_regularizer=l2(0.0001)))\n","model.add(Dense(1, activation='linear'))\n","\n","# Define the Adamax optimizer\n","optimizer = Adamax()\n","\n","model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])"],"metadata":{"id":"ePOzDWcGI8Nl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9e00aa6"},"outputs":[],"source":["# Step 6: Fit the model on the training data\n","early_stopping = EarlyStopping(monitor='val_loss', patience=300, restore_best_weights=True)\n","\n","history = model.fit(X_train_scaled, y_train_scaled, epochs=650, batch_size=7,\n","                    verbose=1, validation_split=0.1, callbacks=[early_stopping])"]},{"cell_type":"code","source":["# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper right')\n","plt.show()"],"metadata":{"id":"W3WkP2FMJHDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: After making predictions, inverse transform the predictions\n","predictions_scaled = model.predict(X_test_scaled)\n","predictions_original_scale = scaler_y.inverse_transform(predictions_scaled)"],"metadata":{"id":"J5NQ-W3BJL9T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: MSE and MAE computations\n","mse = mean_squared_error(y_test, predictions_original_scale)\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","\n","# Calculate the Mean Absolute Error (MAE)\n","mae = mean_absolute_error(y_test, predictions_original_scale)\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"QP1EW-o6JP1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 9: Graph plotting\n","\n","predictions_flat = np.squeeze(predictions_original_scale)\n","actual_values_flat = y_test.values.ravel()  # This will flatten to 1D\n","y_test = y_test.reset_index(drop=True)\n","\n","# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"8vabp4mxJea4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Recurrent Neural Networks"],"metadata":{"id":"lCYlUOVfJtdC"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"FVXEgWRKKije"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73dabb5a"},"outputs":[],"source":["# Define features (X) and target variable (y)\n","X = data.drop(columns=['Concentration'])\n","y = data['Concentration']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0adccd5"},"outputs":[],"source":["# Step 1: Initialize the MinMaxScaler\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()  # Separate scaler for the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2b3f9e7e"},"outputs":[],"source":["# Step 2: Split the data into training and testing sets\n","X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63661b09"},"outputs":[],"source":["# Step 3: Fit and transform the scaler on the training features and target\n","X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bf87811"},"outputs":[],"source":["# Step 4: Transform the testing features and target using the fitted scaler\n","X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b743184c"},"outputs":[],"source":["# Reshape the input data for RNN\n","X_train_scaled_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n","X_test_scaled_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)"]},{"cell_type":"code","source":["# Define the RNN model with L2 regularization\n","model = Sequential()\n","model.add(SimpleRNN(16, input_shape=(X_train_scaled_reshaped.shape[1], X_train_scaled_reshaped.shape[2]), return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(SimpleRNN(8, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(SimpleRNN(4, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(SimpleRNN(2, return_sequences=False, activation=elu, kernel_regularizer=l2(0.001)))  # Last layer\n","model.add(Dense(1, activation='linear'))\n","\n","# Compile the model\n","optimizer = Adamax()\n","model.compile(optimizer=optimizer, loss='mse')"],"metadata":{"id":"CFI2wCnAKtuh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 5: Fit the model on the training data\n","early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n","\n","history = model.fit(X_train_scaled, y_train_scaled, epochs=600, batch_size=7,\n","                \tverbose=1, validation_split=0.1, callbacks=[early_stopping])"],"metadata":{"id":"t7eiQNNuJweo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: After making predictions, inverse transform the predictions\n","predictions_scaled = model.predict(X_test_scaled)\n","predictions_original_scale = scaler_y.inverse_transform(predictions_scaled)"],"metadata":{"id":"6EdbD1u7K1mi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: MSE and MAE computations\n","mse = mean_squared_error(y_test, predictions_original_scale)\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(y_test, predictions_original_scale)\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"KpzLdnYVK3b_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: Graph plotting\n","predictions_flat = np.squeeze(predictions_original_scale)\n","actual_values_flat = y_test.values.ravel()  # This will flatten to 1D\n","y_test = y_test.reset_index(drop=True)\n","\n","# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"vl9HyvbxLDT_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gated Recurrent Networks"],"metadata":{"id":"RA_H9LO3LW7N"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"tXytm0z8Lb9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a52df770"},"outputs":[],"source":["# Define features (X) and target variable (y)\n","X = data.drop(columns=['Concentration'])\n","y = data['Concentration']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7531708"},"outputs":[],"source":["# Step 1: Initialize the MinMaxScaler\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()  # Separate scaler for the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5491673f"},"outputs":[],"source":["# Step 2: Split the data into training and testing sets\n","X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7f82de99"},"outputs":[],"source":["# Step 3: Fit and transform the scaler on the training features and target\n","X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f288a1e9"},"outputs":[],"source":["# Step 4: Transform the testing features and target using the fitted scaler\n","X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbdac594"},"outputs":[],"source":["# Reshape the input data for RNN\n","X_train_scaled_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n","X_test_scaled_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)"]},{"cell_type":"code","source":["# Define the GRU model with L2 regularization\n","model = Sequential()\n","model.add(GRU(16, input_shape=(X_train_scaled_reshaped.shape[1], X_train_scaled_reshaped.shape[2]), return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(GRU(8, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(GRU(4, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(GRU(2, return_sequences=False, activation=elu, kernel_regularizer=l2(0.001)))  # Last layer\n","model.add(Dense(1, activation='linear'))\n","\n","# Compile the model\n","optimizer = Adamax()\n","model.compile(optimizer=optimizer, loss='mse')"],"metadata":{"id":"BZN0lo_BMXbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 5: Fit the model on the training data\n","early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n","\n","history = model.fit(X_train_scaled, y_train_scaled, epochs=600, batch_size=7,\n","                \tverbose=1, validation_split=0.1, callbacks=[early_stopping])"],"metadata":{"id":"AhwgaEPGMZwh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: After making predictions, inverse transform the predictions\n","predictions_scaled = model.predict(X_test_scaled)\n","predictions_original_scale = scaler_y.inverse_transform(predictions_scaled)"],"metadata":{"id":"9fCQpbT8MbvV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: MSE and MAE computations\n","mse = mean_squared_error(y_test, predictions_original_scale)\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(y_test, predictions_original_scale)\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"sTekcTR0MimZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: Graph plotting\n","predictions_flat = np.squeeze(predictions_original_scale)\n","actual_values_flat = y_test.values.ravel()  # This will flatten to 1D\n","y_test = y_test.reset_index(drop=True)\n","\n","# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"XvZcFkbmMk5n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Long Short-Term Memory"],"metadata":{"id":"zHB7z5DBMsW6"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"aflSlR64M0UM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a9c0c0c"},"outputs":[],"source":["# Define features (X) and target variable (y)\n","X = data.drop(columns=['Concentration'])\n","y = data['Concentration']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"171ba12b"},"outputs":[],"source":["# Step 1: Initialize the MinMaxScaler\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()  # Separate scaler for the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7578fe24"},"outputs":[],"source":["# Step 2: Split the data into training and testing sets\n","X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8e15b418"},"outputs":[],"source":["# Step 3: Fit and transform the scaler on the training features and target\n","X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ed0276a"},"outputs":[],"source":["# Step 4: Transform the testing features and target using the fitted scaler\n","X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40bc73aa"},"outputs":[],"source":["# Reshape the input data for LSTM\n","X_train_scaled_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n","X_test_scaled_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)"]},{"cell_type":"code","source":["# Step 5: Define the LSTM model\n","model = Sequential()\n","model.add(LSTM(16, input_shape=(X_train_scaled_reshaped.shape[1], X_train_scaled_reshaped.shape[2]), return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(LSTM(8, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(LSTM(4, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","model.add(LSTM(2, return_sequences=False, activation=elu, kernel_regularizer=l2(0.001)))  # Last layer\n","model.add(Dense(1, activation='elu'))\n","\n","# Compile the model\n","optimizer = Adamax()\n","model.compile(optimizer=optimizer, loss='mse')"],"metadata":{"id":"iIEThCduNQJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Fit the model on the training data\n","early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n","\n","history = model.fit(X_train_scaled, y_train_scaled, epochs=600, batch_size=7,\n","                    verbose=1, validation_split=0.1, callbacks=[early_stopping])"],"metadata":{"id":"AuekW2FVNRzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: After making predictions, inverse transform the predictions\n","predictions_scaled = model.predict(X_test_scaled)\n","predictions_original_scale = scaler_y.inverse_transform(predictions_scaled)"],"metadata":{"id":"7uyBbKZpNUXG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: MSE and MAE computations\n","mse = mean_squared_error(y_test, predictions_original_scale)\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(y_test, predictions_original_scale)\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"HN5PYG4DNZcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 9: Graph plotting\n","predictions_flat = np.squeeze(predictions_original_scale)\n","actual_values_flat = y_test.values.ravel()  # This will flatten to 1D\n","y_test = y_test.reset_index(drop=True)\n","\n","# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"jxqDIFDqNepg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mixed Layer Model"],"metadata":{"id":"TGhfWpmgNyDM"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"mCY94ycmN18v"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16f05747"},"outputs":[],"source":["# Step 1: Initialize the MinMaxScaler\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()  # Separate scaler for the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47300ba8"},"outputs":[],"source":["# Define features (X) and target variable (y)\n","X = data.drop(columns=['Concentration'])\n","y = data['Concentration']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3744211f"},"outputs":[],"source":["# Step 2: Split the data into training and testing sets\n","X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74f474ce"},"outputs":[],"source":["# Step 3: Fit and transform the scaler on the training features and target\n","X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"013b4560"},"outputs":[],"source":["# Step 4: Transform the testing features and target using the fitted scaler\n","X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bc8a646"},"outputs":[],"source":["# Reshape the input data for RNN\n","X_train_scaled_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n","X_test_scaled_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)"]},{"cell_type":"code","source":["# Step 5: Define the model\n","model = Sequential()\n","\n","# Add the first recurrent layer (GRU)\n","model.add(SimpleRNN(16, input_shape=(X_train_scaled_reshaped.shape[1], X_train_scaled_reshaped.shape[2]), return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","\n","# Add the second recurrent layer (LSTM)\n","model.add(SimpleRNN(8, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","\n","# Add the third recurrent layer (SimpleRNN)\n","model.add(SimpleRNN(4, return_sequences=True, activation=elu, kernel_regularizer=l2(0.001)))\n","\n","# Add the fourth recurrent layer (GRU)\n","model.add(GRU(2, return_sequences=False, activation=elu, kernel_regularizer=l2(0.001)))  # Last layer\n","\n","# Add the output layer\n","model.add(Dense(1))\n","\n","# Compile the model\n","optimizer = Adamax()\n","model.compile(optimizer=optimizer, loss='mse')"],"metadata":{"id":"ZOidFGhJOsxx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Fit the model on the training data\n","early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n","\n","history = model.fit(X_train_scaled, y_train_scaled, epochs=600, batch_size=7,\n","                    verbose=1, validation_split=0.1, callbacks=[early_stopping])"],"metadata":{"id":"9tEY7TANOuf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: After making predictions, inverse transform the predictions\n","predictions_scaled = model.predict(X_test_scaled)\n","predictions_original_scale = scaler_y.inverse_transform(predictions_scaled)"],"metadata":{"id":"f2v9KDRgOwLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: MSE and MAE computations\n","mse = mean_squared_error(y_test, predictions_original_scale)\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(y_test, predictions_original_scale)\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"5EIHfLWoO5P8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 9: Graph plotting\n","predictions_flat = np.squeeze(predictions_original_scale)\n","actual_values_flat = y_test.values.ravel()  # This will flatten to 1D\n","y_test = y_test.reset_index(drop=True)\n","\n","# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.savefig(\"mixed_daily_variance.pdf\")\n","plt.show()\n","\n","\n","plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"8rCwjU84O5pP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Autoencoders"],"metadata":{"id":"kGdVufUgPG0y"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"nGfJbN7TPGQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rHFDO1GZx7b"},"outputs":[],"source":["# Define features (X) and target variable (y)\n","X = data.drop(columns=['Concentration'])\n","y = data[['Concentration']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axGS3vcpZx7b"},"outputs":[],"source":["# Step 1: Initialize the MinMaxScaler\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()  # Separate scaler for the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3vk7ThE18Xz"},"outputs":[],"source":["# Set a seed for reproducibility\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXVwC4rBZx7b"},"outputs":[],"source":["# Step 2: Split the data into training and testing sets\n","X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8h_YyT-NZx7b"},"outputs":[],"source":["# Step 3: Fit and transform the scaler on the training features and target\n","X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lekU5WfZx7b"},"outputs":[],"source":["# Step 4: Transform the testing features and target using the fitted scaler\n","X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"]},{"cell_type":"code","source":["# Define the autoencoder architecture\n","n_features = X_train_scaled_reshaped.shape[1]  # This can be adjusted to your specific number of features\n","\n","# Dynamically create input layers\n","input_layers = [Input(shape=(1,)) for _ in range(n_features)]\n","\n","# Concatenate all input layers\n","concatenated_inputs = Concatenate()(input_layers)\n","\n","# Encoder layers\n","encoded = Dense(70, activation='elu', kernel_regularizer=l2(0.0001))(concatenated_inputs)  # First hidden layer\n","encoded = Dense(35, activation='elu', kernel_regularizer=l2(0.0001))(encoded)\n","encoded = Dense(21, activation='elu', kernel_regularizer=l2(0.0001))(encoded)      # Second hidden layer\n","encoded = Dense(14, activation='elu', kernel_regularizer=l2(0.0001))(encoded)      # Third hidden layer\n","encoded = Dense(7, activation='elu', kernel_regularizer=l2(0.0001))(encoded)      # Fourth hidden layer\n","encoded = Dense(1, activation='elu', kernel_regularizer=l2(0.0001))(encoded)  # Encoding layer\n","\n","# Decoder layers\n","decoded = Dense(7, activation='elu', kernel_regularizer=l2(0.0001))(encoded)      # First hidden layer in decoder\n","decoded = Dense(14, activation='elu', kernel_regularizer=l2(0.0001))(decoded)      # Second hidden layer in decoder\n","decoded = Dense(21, activation='elu', kernel_regularizer=l2(0.0001))(decoded)      # Third hidden layer in decoder\n","decoded = Dense(35, activation='elu', kernel_regularizer=l2(0.0001))(decoded)      # Fourth hidden layer in decoder\n","decoded = Dense(70, activation='elu', kernel_regularizer=l2(0.0001))(decoded)\n","decoded = Dense(1, activation='linear')(decoded)\n","\n","autoencoder = Model(inputs=input_layers, outputs=decoded)\n","\n","# Step 5: Compile the model\n","autoencoder.compile(optimizer='adamax', loss='mse', metrics=['mse'])\n","\n","X_train_list = [X_train_scaled[:, i:i+1] for i in range(n_features)]\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)\n","\n","history = autoencoder.fit(X_train_list, y_train_scaled[:, 0], epochs=15000, batch_size=7, verbose=1, validation_split=0.1, callbacks=[early_stopping])"],"metadata":{"id":"CJ-c9gFGRLMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: After making predictions, inverse transform the predictions\n","X_test_list = [X_test_scaled[:, i:i+1] for i in range(n_features)]  # n_features should match the number used during training\n","predictions_scaled = autoencoder.predict(X_test_list)\n","\n","predictions_original_scale = scaler_y.inverse_transform(predictions_scaled)"],"metadata":{"id":"8PGULbKbRUsp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: MSE and MAE computations\n","mse = mean_squared_error(y_test, predictions_original_scale)\n","print(f'Mean Squared Error (MSE): {mse:.2f}')\n","mae = mean_absolute_error(y_test, predictions_original_scale)\n","print(f'Mean Absolute Error (MAE): {mae:.2f}')"],"metadata":{"id":"KZGozh6IRiGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6ZSQTZSxRRr4"},"outputs":[],"source":["predictions_flat = np.squeeze(predictions_original_scale)\n","actual_values_flat = y_test.values.ravel()  # This will flatten to 1D\n","y_test = y_test.reset_index(drop=True)"]},{"cell_type":"code","source":["# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(14, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"wmREvo-uR0a_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"xqst-k8-Rw-f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generative Adversarial Networks"],"metadata":{"id":"4ROa4S91PHLO"}},{"cell_type":"code","source":["data = datas.copy()"],"metadata":{"id":"FAT6NL_ZPHgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"voAxoMuX_Yi3"},"outputs":[],"source":["X = data.drop(columns=['Concentration'])\n","y = data['Concentration']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Nk7-TCY_Y_5"},"outputs":[],"source":["scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOlKRkmolGUD"},"outputs":[],"source":["np.random.seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRdhFlLw_ark"},"outputs":[],"source":["X_test = X.loc[expanded_indices_month]\n","X_train = X.drop(expanded_indices_month)\n","\n","y_test = y.loc[expanded_indices_month]\n","y_train = y.drop(expanded_indices_month)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9ajfpAA_cnn"},"outputs":[],"source":["X_train_scaled = scaler_X.fit_transform(X_train)\n","y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4LRH5wV5_eOH"},"outputs":[],"source":["X_test_scaled = scaler_X.transform(X_test)\n","y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9wawRgu_xM2"},"outputs":[],"source":["# Generator Model\n","def build_generator():\n","    model = Sequential()\n","    model.add(Dense(210, input_dim=X_train_scaled_reshaped.shape[1], activation='elu', kernel_regularizer=l2(0.0001))) # L2 regularization\n","    model.add(Dense(105, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(70, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(35, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(14, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(7, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(1, activation='linear'))\n","    return model\n","\n","# Discriminator Model\n","def build_discriminator():\n","    model = Sequential()\n","    model.add(Dense(210, input_dim=data.shape[1], activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(105, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(70, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(35, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(14, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(7, activation='elu', kernel_regularizer=l2(0.0001)))\n","    model.add(Dense(1, activation='linear'))\n","    return model\n","\n","generator = build_generator()\n","discriminator = build_discriminator()\n","\n","generator.compile(optimizer='Adamax', loss='mse', metrics=['mse'])\n","discriminator.compile(optimizer='Adamax', loss='mse', metrics=['mse'])\n","\n","# GAN Model\n","gan_input = layers.Input(shape=(X_train_scaled_reshaped.shape[1],))\n","generated_y = generator(gan_input)\n","gan_output = discriminator(tf.concat([gan_input, generated_y], axis=1))\n","\n","gan = models.Model(gan_input, gan_output)\n","gan.compile(optimizer='Adamax', loss='binary_crossentropy')\n"]},{"cell_type":"code","source":["def train_gan(generator, discriminator, gan, X_train, y_train, epochs=50000, batch_size=7):\n","      discriminator_losses = []\n","      generator_losses = []\n","      for e in range(epochs):\n","        # Random batch of examples\n","        idx = np.random.randint(0, X_train_scaled.shape[0], batch_size)\n","        real_x = X_train_scaled[idx]\n","        real_y = y_train_scaled[idx]\n","        real_samples = np.concatenate([real_x, real_y], axis=1)\n","\n","        generated_y = generator.predict(real_x)\n","        generated_samples = np.concatenate([real_x, generated_y], axis=1)\n","\n","        # Labels for real and fake data\n","        real_y_disc = np.ones((batch_size, 1))\n","        fake_y_disc = np.zeros((batch_size, 1))\n","\n","        # Discriminator training\n","        discriminator.train_on_batch(real_samples, real_y_disc)\n","        discriminator.train_on_batch(generated_samples, fake_y_disc)\n","\n","        d_loss_real = discriminator.train_on_batch(real_samples, real_y_disc)\n","        d_loss_fake = discriminator.train_on_batch(generated_samples, fake_y_disc)\n","        discriminator_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","        # Generatoror Training\n","        misleading_targets = np.ones((batch_size, 1))\n","        generator_loss = gan.train_on_batch(real_x, misleading_targets)\n","        gan.train_on_batch(real_x, misleading_targets)\n","        discriminator_losses.append(discriminator_loss)\n","        generator_losses.append(generator_loss)\n","        if e % 250 == 0:\n","            print(f'Epoch {e + 1}/{epochs}, Loss: {discriminator.evaluate(real_samples, real_y_disc, verbose=0)}')\n","      return discriminator_losses, generator_losses\n","\n","discriminator_losses, generator_losses = train_gan(generator, discriminator, gan, X_train_scaled, y_train_scaled)"],"metadata":{"id":"k_Bsc5mHSekv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_y_test = generator.predict(X_test_scaled)\n","predicted_y_test = scaler_y.inverse_transform(generated_y_test)"],"metadata":{"id":"IoBCDp1RSgGX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mse = mean_squared_error(y_test, predicted_y_test)\n","print(\"Mean Squared Error:\", mse)\n","\n","mae = mean_absolute_error(y_test, predicted_y_test)\n","print(\"Mean Absolute Error:\", mae)"],"metadata":{"id":"pB95OlsGXPD-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nabBH1VsIgW5"},"outputs":[],"source":["lossdiscriminator = []\n","for i in range(len(discriminator_losses)):\n","    discriminatorlosses = (discriminator_losses[i][0] + discriminator_losses[i][1]) /2\n","    lossdiscriminator.append(discriminatorlosses)"]},{"cell_type":"code","source":["plt.figure(figsize=(10, 5))\n","plt.plot(lossdiscriminator, label='Discriminator Loss')\n","plt.plot(generator_losses, label='Generator Loss')\n","plt.title('Training Losses of GAN')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"hzbeB9E2g7a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1H9PGicxSVBE"},"outputs":[],"source":["predictions_flat = np.squeeze(predicted_y_test)\n","actual_values_flat = y_test.values.ravel()  # This will flatten to 1D\n","y_test = y_test.reset_index(drop=True)"]},{"cell_type":"code","source":["# Create a DataFrame combining y_test and predictions_original_scale\n","results_df = pd.DataFrame({'Actual_Concentration': actual_values_flat, 'Predicted_Concentration': predictions_flat}, index=y_test.index)\n","\n","# Plotting actual vs predicted\n","plt.figure(figsize=(10, 6))\n","plt.scatter(results_df['Actual_Concentration'], results_df['Predicted_Concentration'], color='orange', label='Predicted vs Actual')\n","\n","# Add diagonal line for perfect predictions\n","plt.plot(results_df['Actual_Concentration'], results_df['Actual_Concentration'], color='blue', linestyle='--', label='Perfect Prediction')\n","\n","plt.xlabel('Actual Concentration', fontsize = 16)\n","plt.ylabel('Predicted Concentration', fontsize = 16)\n","plt.legend(prop={'size': 12})\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"XcxbN6KcSpGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(14, 6))\n","\n","plt.scatter(results_df.index, results_df['Actual_Concentration'], label='Actual Concentration', color='blue')\n","plt.scatter(results_df.index, results_df['Predicted_Concentration'], label='Predicted Concentration', color='orange', marker='x')\n","\n","\n","for i in results_df.index:\n","    actual = results_df['Actual_Concentration'][i]\n","    predicted = results_df['Predicted_Concentration'][i]\n","    line_color = 'black' if actual > predicted else 'red'\n","    plt.plot([i, i], [actual, predicted], color=line_color, linestyle='--', linewidth=1)\n","\n","plt.xlabel('Test Sample Index', fontsize = 16)\n","plt.ylabel('Concentration', fontsize = 16)\n","\n","legend_elements = [\n","    Line2D([0], [0], color='blue', lw=0, marker='o', label='Actual Concentration', markersize=10),\n","    Line2D([0], [0], color='orange', lw=0, marker='x', label='Predicted Concentration', markersize=10),\n","    Line2D([0], [0], color='black', lw=1, linestyle='--', label='Actual > Predicted'),\n","    Line2D([0], [0], color='red', lw=1, linestyle='--', label='Actual < Predicted')\n","]\n","\n","plt.legend(handles=legend_elements, loc='upper right', prop={'size': 11})\n","plt.xticks([])\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"07VQE0fRSsT6"},"execution_count":null,"outputs":[]}]}